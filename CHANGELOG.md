# Changelog

Todas as mudanÃ§as notÃ¡veis neste projeto serÃ£o documentadas neste arquivo.

O formato Ã© baseado em [Keep a Changelog](https://keepachangelog.com/pt-BR/1.0.0/),
e este projeto adere ao [Semantic Versioning](https://semver.org/lang/pt-BR/).

## [1.0.0] - 2025-08-07

### Adicionado
- âœ¨ **Motor de IA prÃ³prio (SevenXEngine)** - Independente, baseado em PyTorch
- ğŸ’¬ **Chat interativo funcionando** - Respostas reais de modelos locais
- ğŸ¤– **Suporte a DialoGPT** - Small, Medium, Large testados e funcionando
- ğŸ“Š **Monitor de sistema completo** - CPU, RAM, processos em tempo real
- ğŸ¨ **Interface moderna PyQt6** - Tema escuro, responsiva
- ğŸ”§ **5 abas de configuraÃ§Ãµes** - Geral, Modelos, Chat, Interface, AvanÃ§ado
- ğŸ“¦ **Sistema de build robusto** - Criar executÃ¡vel .exe standalone
- ğŸ—‚ï¸ **Gerenciamento de modelos** - Download, instalaÃ§Ã£o, mapeamento inteligente
- ğŸ” **Sistema de logs detalhado** - Debug e troubleshooting
- ğŸ’¾ **ConfiguraÃ§Ãµes persistentes** - Salvar preferÃªncias do usuÃ¡rio
- ğŸš€ **Scripts de instalaÃ§Ã£o** - Setup automatizado para Windows
- ğŸ§ª **Testes automatizados** - Verificar funcionamento de modelos

### CaracterÃ­sticas TÃ©cnicas
- Desenvolvido em Python com PyQt6
- Arquitetura modular e extensÃ­vel
- Suporte a mÃºltiplos modelos simultaneamente
- Threading para operaÃ§Ãµes nÃ£o-bloqueantes
- Sistema de cache inteligente
- ConfiguraÃ§Ãµes persistentes

### Modelos Suportados
- Llama 2 (7B, 13B, 70B)
- Mistral 7B
- Code Llama
- Vicuna
- Orca Mini
- Neural Chat
- StarCode
- E todos os modelos compatÃ­veis com Ollama

### Requisitos do Sistema
- Python 3.8+
- 4GB+ RAM (recomendado)
- Windows 10/11, macOS, Linux
- GPU opcional para melhor performance