<div align="center">

PortuguÃªs do Brasil | English

</div>

ğŸš€ PortuguÃªs do Brasil
<div align="center">

Uma plataforma de IA desktop, local e privada. Execute, gira e converse com modelos de linguagem open-source com total controlo e performance.

ğŸ“¥ Baixar a Ãšltima VersÃ£o â€¢ ğŸ› Reportar um Bug â€¢ ğŸ’¬ Iniciar uma DiscussÃ£o

</div>

âœ¨ Funcionalidades Principais
Multi-Backend FlexÃ­vel: Escolha como executar os seus modelos:

ğŸ¤– SevenX Engine (Local): Motor de inferÃªncia integrado para modelos Hugging Face, otimizado para rodar localmente em CPU e GPU (NVIDIA).

ğŸ¦™ IntegraÃ§Ã£o com Ollama: Conecte-se ao seu servidor Ollama para usar qualquer modelo da sua biblioteca, incluindo os quantizados (GGUF).

âš¡ Performance Otimizada:

Streaming em Tempo Real: Receba respostas do modelo palavra por palavra para uma experiÃªncia de chat fluida.

Modo Leve: Ative para reduzir o consumo de CPU em computadores com menos recursos.

GestÃ£o de MemÃ³ria Inteligente: Apenas um modelo fica ativo na memÃ³ria por vez, economizando RAM.

ğŸ¤— Gestor de Modelos Hugging Face:

Pesquise, baixe e gira milhares de modelos diretamente do Hugging Face Hub.

Suporte para modelos protegidos atravÃ©s de token de acesso.

ğŸ“Š Monitor de Sistema Completo:

Acompanhe o uso de CPU, RAM e Disco.

Monitoramento de GPU NVIDIA: Veja o uso de VRAM, a utilizaÃ§Ã£o e a temperatura da sua placa de vÃ­deo.

ğŸ”’ Privacidade Total: Tudo roda na sua mÃ¡quina. Os seus dados, prompts e conversas nunca saem do seu computador.

ğŸ¨ Interface Moderna e ConfigurÃ¡vel:

UI responsiva construÃ­da com PyQt6.

Personalize parÃ¢metros de geraÃ§Ã£o, tema visual, e mais na aba de configuraÃ§Ãµes.

ğŸ› ï¸ InstalaÃ§Ã£o
Windows (MÃ©todo RÃ¡pido)
# 1. Instala as dependÃªncias num ambiente virtual
install.bat

# 2. Executa a aplicaÃ§Ã£o
run.bat

Manual (Para todos os sistemas)
# 1. Clone o repositÃ³rio
git clone [https://github.com/sevenx777-dev/SevenX-Studio.git](https://github.com/sevenx777-dev/SevenX-Studio.git)
cd SevenX-Studio

# 2. Crie e ative um ambiente virtual
python -m venv venv
# No Windows:
venv\Scripts\activate
# No Linux/macOS:
# source venv/bin/activate

# 3. Instale as dependÃªncias
pip install -r requirements.txt

# 4. Execute a aplicaÃ§Ã£o
python main.py

ğŸ¯ Como Usar
Execute a AplicaÃ§Ã£o: Inicie o SevenX Studio.

Escolha o ServiÃ§o: Na aba "Chat", selecione se quer usar os modelos locais (SevenX (Local)) ou os do Ollama.

Selecione um Modelo:

Se escolheu Ollama, a lista mostrarÃ¡ os modelos que vocÃª jÃ¡ tem no Ollama.

Se escolheu SevenX (Local), vÃ¡ para a aba "Modelos" para pesquisar e baixar modelos do Hugging Face.

Converse: Volte para a aba "Chat", digite a sua mensagem e pressione Enter!

ğŸ¤ Contribuindo
ContribuiÃ§Ãµes sÃ£o muito bem-vindas! Se tem uma ideia ou encontrou um bug, por favor, abra uma Issue ou um Pull Request.

ğŸ“„ LicenÃ§a
Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT. Veja o ficheiro LICENSE para mais detalhes.

ğŸš€ English
<div align="center">

A modern, local, and private desktop AI platform. Run, manage, and chat with open-source language models with full control and performance.

ğŸ“¥ Download Latest Release â€¢ ğŸ› Report a Bug â€¢ ğŸ’¬ Start a Discussion

</div>

âœ¨ Key Features
Flexible Multi-Backend: Choose how to run your models:

ğŸ¤– SevenX Engine (Local): Integrated inference engine for Hugging Face models, optimized to run locally on CPU and GPU (NVIDIA).

ğŸ¦™ Ollama Integration: Connect to your Ollama server to use any model from its library, including quantized models (GGUF).

âš¡ Optimized Performance:

Real-Time Streaming: Receive model responses word-by-word for a fluid chat experience.

Lite Mode: Enable to reduce CPU consumption on less powerful computers.

Smart Memory Management: Only one model remains active in memory at a time, saving RAM.

ğŸ¤— Hugging Face Model Manager:

Search, download, and manage thousands of models directly from the Hugging Face Hub.

Support for gated models via access token.

ğŸ“Š Comprehensive System Monitor:

Track CPU, RAM, and Disk usage.

NVIDIA GPU Monitoring: View VRAM usage, utilization, and the temperature of your graphics card.

ğŸ”’ Total Privacy: Everything runs on your machine. Your data, prompts, and conversations never leave your computer.

ğŸ¨ Modern and Configurable UI:

Responsive UI built with PyQt6.

Customize generation parameters, visual theme, and more in the settings tab.

ğŸ› ï¸ Installation
Windows (Quick Method)
# 1. Installs dependencies in a virtual environment
install.bat

# 2. Runs the application
run.bat

Manual (All Systems)
# 1. Clone the repository
git clone [https://github.com/sevenx777-dev/SevenX-Studio.git](https://github.com/sevenx777-dev/SevenX-Studio.git)
cd SevenX-Studio

# 2. Create and activate a virtual environment
python -m venv venv
# On Windows:
venv\Scripts\activate
# On Linux/macOS:
# source venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the application
python main.py

ğŸ¯ How to Use
Run the Application: Start SevenX Studio.

Choose the Service: In the "Chat" tab, select whether you want to use local models (SevenX (Local)) or those from Ollama.

Select a Model:

If you chose Ollama, the list will show the models you already have in Ollama.

If you chose SevenX (Local), go to the "Models" tab to search for and download models from Hugging Face.

Chat: Return to the "Chat" tab, type your message, and press Enter!

ğŸ¤ Contributing
Contributions are very welcome! If you have an idea or have found a bug, please open an Issue or a Pull Request.

ğŸ“„ License
This project is licensed under the MIT License. See the LICENSE file for details.
